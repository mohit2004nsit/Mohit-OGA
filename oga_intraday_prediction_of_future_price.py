# -*- coding: utf-8 -*-
"""OGA Intraday Prediction of future price.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1FhaFrTdblTqSAR7sU1H_ZkAXKC-ZAWWv
"""

import random
from sklearn.datasets import make_classification
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score
from sklearn.svm import SVC
import pandas as pd

!pip install yfinance
#!pip install mplfinance
import yfinance as yf

global symbol, df, start_date, end_date
df = pd.DataFrame()
symbol = 'NIFTY_FIN_SERVICE.NS'          # ^NSEI, ^NSEBANK

n = 59  # number of days

# Get the current timestamp
current_date = pd.Timestamp.now(tz='Asia/Kolkata')

# Calculate the start date by subtracting n days from the current date
start_date = current_date - pd.Timedelta(days=n)

#start_date = pd.Timestamp('2023-2-25 09:00:00', tz='Asia/Kolkata')
#end_date = pd.Timestamp('2023-8-1 15:30:00', tz='Asia/Kolkata')
end_date = pd.to_datetime('2023-08-15 10:30') #'2023-08-04'  #pd.to_datetime('2023-03-10 15:30')
interval = '5m'
def download_data(df):
  df = yf.download(symbol,
                   start=start_date
                     #,end=end_date
                     ,interval = interval
                     ,progress=False)
  return df
df = download_data(df)
if df.index.name=='Datetime':
  df.index.name = 'Date'

dataset=df
#ataset.columns = ['Price']
dataset.tail()

"""**Define Parameters**"""

start_t = 0
jump = 30
no_of_generation = 5
real_test_data = 0  #1= reserve test data, 0 = predict for future dates
n_pred = int(jump)
print(n_pred)

import pandas as pd
from pandas.tseries.offsets import BDay
from datetime import datetime
# Define the number of future business days to generate
num_days = n_pred

# Get today's date
#today = pd.Timestamp.today().normalize()
start = dataset.index[-1] # specify start date and time
# Generate a list of future business day dates
future_dates = pd.date_range(start=start, periods=num_days, freq='5min') # freq 5min, BDay()
df2 = pd.DataFrame(index=future_dates, columns=dataset.columns)
#df2['Date'] = pd.DataFrame(future_dates)
# Print the list of future business day dates
print(df2)

if real_test_data!=1:
  dataset = dataset.append(df2)
  dataset.index.name = 'Date'
dataset.tail()

dataset.reset_index(inplace=True)

dataset['index_num'] = range(1, len(dataset)+1)

dataset.set_index('index_num', inplace=True)
dataset.tail()

dataset.Close = (dataset.Open +	dataset.High +	dataset.Low +	dataset.Close)/4
dataset.Close.plot()

cnt = len(dataset["Close"])
tr = cnt - n_pred

"""**Auto Regression**"""

train, test = dataset["Close"][0:tr], dataset["Close"][tr:]

lags = 5*n_pred

import numpy as np
from sklearn.metrics import mean_squared_error
from math import sqrt
from statsmodels.tsa.ar_model import AutoReg
import warnings
warnings.filterwarnings("ignore")

model = AutoReg(train, lags=lags) #AutoReg
model_fit = model.fit()

fit_ar = model_fit.fittedvalues

predictions = model_fit.forecast(n_pred)  # 95% conf #,

arima_pred_static = np.array(predictions)

fit_ar = fit_ar.to_numpy().reshape(-1,1)
predictions = predictions.to_numpy().reshape(-1,1)

predictions.max(), predictions.min()

import matplotlib.pyplot as plt

plt.figure(figsize = (12,6))
plt.plot(dataset.iloc[lags:tr].index, train[lags:tr], color= 'black', label= 'Train Data')
plt.plot(dataset.iloc[lags:tr].index, fit_ar, color= 'Blue', label= 'Fit Data')

if real_test_data==1:
  plt.plot(dataset.iloc[tr:].index,test, color= 'green', label= 'Test Data')
plt.plot(dataset.iloc[tr:].index,predictions, color= 'red', label= 'AR model')
#plt.plot(airline_df.iloc[tr:].index,arima_pred_static, color= 'green', label= 'ARIMA Model')
plt.xlabel('Date')
plt.ylabel('Price')
plt.legend()
#plt.savefig(symbol+''+title+'.png', format='png', figsize=(5,4), dpi=300)
plt.show()

dataset.iloc[lags:tr].Close

from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error
fit_rmse = mean_squared_error(train[lags:], fit_ar, squared=False)
if real_test_data==1:
  test_rmse = mean_squared_error(test, np.array(predictions), squared=False)
fit_mape = mean_absolute_percentage_error(train[lags:],fit_ar)*100
if real_test_data==1:
  test_mape = mean_absolute_percentage_error(test,np.array(predictions))*100

print(round(fit_rmse,2))
print(round(fit_mape,2))

if real_test_data==1:
  print(round(test_rmse,2))
  print(round(test_mape,2))

"""**Rolling Window forward validation Genetic Algorithm**"""

import numpy as np
import matplotlib.dates as mdates
from sklearn.preprocessing import MinMaxScaler
trans = MinMaxScaler()


#cnt = len(dataset["Close"])
#tr = int(cnt - n_pred)
#tt = cnt - tr

dataset_copy = dataset.copy()
#dataset_copy.reset_index(inplace=True)

# convert to ints
dataset_copy['Date'] = dataset_copy.index

dataset_close = np.reshape(dataset_copy["Close"].values,(len(dataset_copy["Close"].values),1))
dataset_norm = trans.fit_transform(dataset_close)


train_x, train_y_scaled, train_y,  test_x, test_y_scaled, test_y = (dataset_copy.Date[lags:tr].values,dataset_norm[lags:tr],
                                                                    dataset_copy["Close"][lags:tr].values,
dataset_copy.Date[tr:].values, dataset_norm[tr:],dataset_copy.Close[tr:].values)

#train_y_scaled = train_y
# Store the original dates for plotting the predicitons
org_dates = dataset_copy['Date']

train_x = np.reshape(train_x,(len(train_x),1))
#train_y_scaled = np.reshape(train_y_scaled,(len(train_y_scaled),1))
test_x = np.reshape(test_x,(len(test_x),1))

"""**Combine AR with machine learning**"""

#train_x = np.append(train_x, fit_ar, axis=1)  #if uncommented then combine
#test_x = np.append(test_x, predictions, axis=1) #if uncommented then combine

scaler = MinMaxScaler(feature_range=(0, 1))
train_x_scaled = scaler.fit_transform(train_x)
test_x_scaled = scaler.transform(test_x)

from sklearn.svm import SVR
import numpy as np
np.set_printoptions(suppress=True)

n_features = 1
g = 1 / (n_features * train_x_scaled[:-lags].var())
g

vol = train_x_scaled[:-lags].std()/lags
vol

import numpy as np
c_list = [  0.1,0.5, 1, 2.5, 5, 7.5, 10]
e_list = [ .0001*vol,.005*vol,.01*vol, .025*vol, .05*vol, .1*vol]
g_list = [ .01*g, 0.1*g,.5*g, 10*g, 20*g, 30*g, 40*g, 50*g, 75*g, 100*g ]
#g_list = [100*g]

"""**Genetic Algorithm**"""

# Define the fitness function
def fitness(individual):
    # Train a logistic regression model with the individual's parameter values
    model = SVR(C=individual[0], epsilon=individual[1], gamma=individual[2])
    len_round = (len(train_x_scaled)//jump)*jump-jump
    fit_rmset = []
    for i in range(start_t,len_round,jump):
      #print(i,i+jump)
      model.fit(train_x_scaled[i:(i+jump)], train_y_scaled[i:(i+jump)])
      fit_ys = model.predict(train_x_scaled[(i+jump):(i+jump+jump)])
      fit_ysr = np.reshape(fit_ys,(len(fit_ys),1))
      fit_y = trans.inverse_transform(fit_ysr)
      # Evaluate the model's accuracy on the dataset
      fit_rmse1 = mean_squared_error(train_y[(i+jump):(i+jump+jump)], fit_y, squared=False)
      fit_rmset.append(fit_rmse1)
    fit_rmse = np.mean(fit_rmset)
    #print(fit_rmse)
    return fit_rmse

import random

# Define the genetic algorithm
def genetic_algorithm(population, fitness_fn, n_generations):
    for generation in range(n_generations):
        print("Generation: ", generation+1)
        # Evaluate the fitness of each individual
        population = [(individual, fitness_fn(individual)) for individual in population]
        # Sort the population by fitness
        population = [individual for individual, fitness in sorted(population, key=lambda x: x[1], reverse=False)]
        #print(population)
        # Select the top individuals for breeding
        parents = population[:int(len(population) / 2)]
        # Perform crossover and mutation to create the next generation
        children = []
        for i in range(len(parents)):
            parent1 = parents[i]
            parent2 = parents[len(parents) - i - 1]
            child = []
            for j in range(len(parent1)):
                if random.random() < 0.1:
                    child.append(parent1[j])
                else:
                    child.append(parent2[j])
            # Perform mutation
            for j in range(len(child)):
                if random.random() < 0.1:
                    if j == 0:
                        child[j] = random.uniform(min(c_list), max(c_list))
                    elif j == 1:
                        child[j] = random.uniform(min(e_list), max(e_list))
                    else:
                        child[j] = random.uniform(min(g_list), max(g_list))
            children.append(child)
        population = parents + children
    return population[0]

#c_list

population = [[i,j,k] for i in (c_list) for j in (e_list) for k in (g_list)]

#population

# Run the genetic algorithm
np.set_printoptions(suppress=True)
import warnings
from sklearn.exceptions import DataConversionWarning
warnings.filterwarnings(action='ignore', category=DataConversionWarning)
best_parameters = genetic_algorithm(population, fitness, no_of_generation)

print("Best parameters: ", best_parameters)

model = SVR(C=best_parameters[0],epsilon=best_parameters[1],gamma=best_parameters[2])
#model_rev = SVR(C=best_parameters[0],epsilon=best_parameters[1],gamma=best_parameters[2])
#model = SVR(C=100,epsilon=.1)
model.fit(train_x_scaled, train_y_scaled)

print(model.score(train_x_scaled, train_y_scaled))
fit_ys = model.predict(train_x_scaled)
fit_ysr = np.reshape(fit_ys,(len(fit_ys),1))
fit_gasvr = trans.inverse_transform(fit_ysr)
# Evaluate the model's accuracy on the dataset
#fit_rmse = mean_squared_error(train_y, fit_y, squared=False)


pred = model.predict(test_x_scaled)
pre_svr = np.reshape(pred,(len(pred),1))
pred_gasvr = trans.inverse_transform(pre_svr)
#print(model.score(test_x_scaled, test_y_scaled))

pred_gasvr.max(), pred_gasvr.min()

import matplotlib.pyplot as plt
title = 'Genetic Algo'
plt.figure(figsize = (12,6))
plt.plot(dataset.iloc[lags:tr].index, train_y, color= 'black', label= 'Train Data')
plt.plot(dataset.iloc[lags:tr].index, fit_gasvr, color= 'Blue', label= 'Fit Data')
if real_test_data==1:
  plt.plot(dataset.iloc[tr:].index,test_y, color= 'green', label= 'Test Data')
plt.plot(dataset.iloc[tr:].index,pred_gasvr, color= 'red', label= 'OGA-SVR')

#plt.plot(airline_df.iloc[tr:].index,arima_pred_static, color= 'green', label= 'ARIMA Model')
plt.xlabel('Date')
plt.ylabel('Price')
plt.legend()
#plt.savefig(symbol+''+title+'.png', format='png', figsize=(5,4), dpi=300)
plt.show()

from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error
fit_rmse = mean_squared_error(train_y, fit_gasvr, squared=False)
if real_test_data==1:
  test_rmse = mean_squared_error(test_y, pred_gasvr, squared=False)
fit_mape = mean_absolute_percentage_error(train_y,fit_gasvr)*100
if real_test_data==1:
  test_mape = mean_absolute_percentage_error(test_y,pred_gasvr)*100

print(round(fit_rmse,2))
print(round(fit_mape,2))

if real_test_data==1:
  print(round(test_rmse,2))
  print(round(test_mape,2))

max(pred_gasvr), min(pred_gasvr)

import plotly.graph_objs as go
from plotly.subplots import make_subplots

# Create figure with subplots
fig = make_subplots(rows=1, cols=1)

# Add Train Data trace
fig.add_trace(go.Scatter(x=dataset.iloc[lags:tr].index, y=train_y, mode='lines', name='Train Data', line=dict(color='black')))

# Add Fit Data trace
#fig.add_trace(go.Scatter(x=dataset.iloc[lags:tr].index, y=fit_gasvr.flatten(), mode='lines', name='Fit Data'))

# Add Test Data trace if applicable
if real_test_data == 1:
    fig.add_trace(go.Scatter(x=dataset.iloc[tr:].index, y=test_y, mode='lines', name='Test Data', line=dict(color='green')))

# Add SVR model trace
fig.add_trace(go.Scatter(x=dataset.iloc[tr:].index, y=pred_gasvr.flatten(), mode='lines', name='SVR Prediction', line=dict(color='red')))

# Add Predictions trace
fig.add_trace(go.Scatter(x=dataset.iloc[tr:].index, y=predictions.flatten(), mode='lines', name='AR', line=dict(color='orange')))

# Set x and y axis labels
fig.update_xaxes(title_text='Date')
fig.update_yaxes(title_text='Price')

# Set layout title
fig.update_layout(title=title, width=900, height=500, showlegend=True,
                  legend=dict(x=0.5, y=1.1, orientation='h'))

# Show plot
fig.show()

"""**AR + ML**"""

dataset["Close"]

fit_gasvr

# Create a DataFrame from fit_gasvr with the specified index
fit_gasvr_df = pd.DataFrame(fit_gasvr, index=dataset.iloc[lags:tr].index)

# Append the fit_gasvr_df DataFrame as a new column to the dataset DataFrame
fit_gasvr_df['Close'] = dataset['Close']

fit_gasvr_df.plot()

fit_gasvr_df.rename(columns={0: 'Fit_Gasvr'}, inplace=True)
fit_gasvr_df

train, test = fit_gasvr_df['Fit_Gasvr'][0:tr], fit_gasvr_df['Fit_Gasvr'][tr:]

train

import numpy as np
from sklearn.metrics import mean_squared_error
from math import sqrt
from statsmodels.tsa.ar_model import AutoReg
import warnings
warnings.filterwarnings("ignore")

# Create and fit the AutoReg model
model = AutoReg(train, lags=lags)
model_fit = model.fit()

# Calculate the fitted values
fit_ar = model_fit.fittedvalues

# Forecast future values
predictions = model_fit.forecast(steps=n_pred)

# Convert predictions to a NumPy array
arima_pred_static = np.array(predictions)

import matplotlib.pyplot as plt

plt.figure(figsize = (12,6))
plt.plot(dataset.iloc[lags:tr].index, train[lags:tr], color= 'black', label= 'Train Data')
plt.plot(dataset.iloc[lags:tr].index, fit_ar, color= 'Blue', label= 'Fit Data')

if real_test_data==1:
  plt.plot(dataset.iloc[tr:].index,test, color= 'green', label= 'Test Data')
plt.plot(dataset.iloc[tr:].index,predictions, color= 'red', label= 'AR model')
#plt.plot(airline_df.iloc[tr:].index,arima_pred_static, color= 'green', label= 'ARIMA Model')
plt.xlabel('Date')
plt.ylabel('Price')
plt.legend()
#plt.savefig(symbol+''+title+'.png', format='png', figsize=(5,4), dpi=300)
plt.show()

"""**Consolidated Result**"""

from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error

fit_rmse_ar = mean_squared_error(train[lags:], fit_ar, squared=False)
if real_test_data==1:
  test_rmse_ar = mean_squared_error(test, np.array(predictions), squared=False)
fit_mape_ar = mean_absolute_percentage_error(train[lags:],fit_ar)*100
if real_test_data==1:
  test_mape_ar = mean_absolute_percentage_error(test,np.array(predictions))*100


fit_rmse_gasvr = mean_squared_error(train_y, fit_gasvr, squared=False)
if real_test_data==1:
  test_rmse_gasvr = mean_squared_error(test_y, pred_gasvr, squared=False)
fit_mape_gasvr = mean_absolute_percentage_error(train_y,fit_gasvr)*100
if real_test_data==1:
  test_mape_gasvr = mean_absolute_percentage_error(test_y,pred_gasvr)*100


print('     AR:',round(fit_rmse_ar,2), round(fit_mape_ar,2))
print('OGA-SVR:',round(fit_rmse_gasvr,2),  round(fit_mape_gasvr,2))

if real_test_data==1:
  print('---Test---')
  print('     AR:',round(test_rmse_ar,2), round(test_mape_ar,2))
  print('OGA-SVR:',round(test_rmse_gasvr,2),  round(test_mape_gasvr,2))

import matplotlib.pyplot as plt

title = 'Prediction by Models on NIFTY'
#plt.figure(figsize = (3,2),dpi=300)
plt.plot(dataset.index, dataset.Close, color= 'black', label= 'Close Price')

plt.plot(dataset.iloc[lags:].index,np.append(fit_ar,predictions), color= 'darkorange', label= 'AR')

plt.plot(dataset.iloc[lags:].index,np.append(fit_gasvr,pred_gasvr), color= 'green', label= 'GA-SVR')


plt.axvline(x = dataset.iloc[tr-1:tr].index, ymin = 0, ymax = 1,
           color = 'gray'
           )

plt.legend(loc="upper left", ncol=1, fontsize='small')
plt.title(title)

plt.xlabel('Date')
plt.ylabel('Price')
plt.xticks(rotation=30)
#plt.legend()
plt.savefig(symbol+title+'.png', format='png', dpi=300, bbox_inches='tight')
plt.show()